---
title: "Simons_document"
author: "Simon Jorstedt"
date: "`r Sys.Date()`"
output: pdf_document
---


# Assignment 3

## Setup

```{r}
library(magrittr)
library(dplyr)
library(caret)

crime_df <- read.csv("communities.csv")
```

## Assignment 3.1
We are given some crime data. From analysing it using PCA, we find that the first component (PC1) explains $98.574$% of the variance, and the second component (PC2) explains $0.396$% of the variance in the data. As such, only one component is needed to capture at least $95$% of the variance in the data.

```{r}
# Assignment 3.1

# Establish a scaler for the entire dataset
scaler_crime1 <- crime_df %>%
  select(-"ViolentCrimesPerPop") %>%
  preProcess()

# Rescale the entire dataset and create X_crime
X_crime <- crime_df %>%
  select(-"ViolentCrimesPerPop") %>%
  predict(scaler_crime1, .) %>%
  as.matrix()

# Compute sample covariance matrix for X_crime
S_crime <- (1/nrow(X_crime)) * t(X_crime) %*% X_crime

# Calculate eigenvalues for the sample covariance matrix
U_crime <- eigen(S_crime)

# Calculate the percentage of variance explained by each PC
var_explained <- (100*U_crime$values / sum(U_crime$values)) %>%
  round(digits = 3)

cat("Variance explained by PC1:", var_explained[1] %>% sum(), "%\n")

cat("Variance explained by PC2:", var_explained[2] %>% sum(), "%\n")

# 35 PC's needed to achieve at least 95% variance explained
cat("Variance explained by first 35 PC's:",
    var_explained[1:35] %>% sum(), "%\n")
```


## Assignment 3.2
```{r}
# Assignment 3.2

PCA_2 <- princomp(crime_df %>% select(-"ViolentCrimesPerPop"))

# U contains the PC loadings
# The eigenvectors basically (columnwise)
U <- PCA_2$loadings

plot(U[,1], main="Fig 3.2. Traceplot, PC1")
```

In Figure 3.2 we see that the first feature of PC1 (state) carries by far the most explanatory power. The four following ones are population, household size, raceb, racew. These features might be related to each other.

Next, in Figure 3.3 we plot the PC scores of PC1 and PC2, and map the color of points to the Violent Crimes per Population feature.

```{r}
plot(U[,1], U[,2], main="Fig 3.3. PC Scores")
```

## Assignment 3.3

```{r, echo=F}
# Assignment 3.3

## Split data into train and test
n = nrow(crime_df)
set.seed(12345)
id=sample(1:n, floor(n*0.5))
train=crime_df[id,]
test=crime_df[-id,]

```

```{r}
# Establish Scaling
scaling <- train %>% preProcess()

# Scale train and test data
train <- predict(scaling, train)
test <- predict(scaling, test)

# Train lin reg model
model1 <- lm(data = train,
             formula = ViolentCrimesPerPop ~ .)

# Compute train error (MSE)
train_mse <- mean((train$ViolentCrimesPerPop - model1$fitted.values)^2)

# Predict new responses for the test data
test_pred <- predict(model1,
                     test[,-which(names(test) == "ViolentCrimesPerPop")])
test_mse <- mean((test$ViolentCrimesPerPop - test_pred)^2)

cat("Train mse:", train_mse, "\n")
cat("Test mse:", test_mse, "\n")
```

## Assignment 3.4

```{r}
## Assignment 3.4

train_noresponse <- train[,-which(names(train) == "ViolentCrimesPerPop")]
y_true_train <- train[,which(names(train) == "ViolentCrimesPerPop")]

test_noresponse <- test[,-which(names(test) == "ViolentCrimesPerPop")]
y_true_test <- test[,which(names(test) == "ViolentCrimesPerPop")]

train_errors <- c()
test_errors <- c()
test_prints <- c(3)

# cost function
# data should NOT contain the response variable
# No intercept is included in the underlying model
cost_linreg <- function(theta){
  
  # Calculate train error
  y_pred_train <- as.matrix(train_noresponse) %*% theta
  train_cost <- mean((y_pred_train - y_true_train)^2)
  train_errors <<- c(train_errors, train_cost)
  
  # Calculate test error
  y_pred_test <- as.matrix(test_noresponse) %*% theta
  test_cost <- mean((y_pred_test - y_true_test)^2)
  test_errors <<- c(test_errors, test_cost)
  
  return(train_cost)
}

optim_object <- optim(rep(0, 100), method="BFGS", fn = cost_linreg, control = list(trace=T))

cat(test_prints, "\n")
```


```{r}
# Iterate and stuff
# theta <- rep(0, 100)
# train_errors <- c()
# test_errors <- c()
# for(i in 1:1000){
#   cat(i, " ")
#   optim_object <- optim(theta, method="BFGS", fn = cost_linreg)
#   
#   # Compute and store train error
#   train_prediction <- as.matrix(train_noresponse) %*% optim_object$par
#   train_errors <- c(train_errors, mean((train_prediction - y_true)^2))
#   
#   # Compute and store test error
#   test_noresponse <- test[,-which(names(test) == "ViolentCrimesPerPop")]
#   test_prediction <- as.matrix(test_noresponse) %*% optim_object$par
#   test_errors <- c(test_errors, mean((test_prediction - y_true)^2))
#   
#   # Update theta
#   theta <- optim_object$par
# }

ylim <- c(min(train_errors[-c(1:500)], test_errors[-c(1:500)]), max(train_errors[-c(1:500)], test_errors[-c(1:500)]))
plot(test_errors[-c(1:500)], type="l", col="red", ylim = ylim)
points(train_errors[-c(1:500)], type="l", col="blue")
```



# Questions
What is the difference between `prcomp` and `princomp`? Why do we redo the PCA after we have already done it in 3.1?

Why are all the diagonal elements equal in the sample covariance matrix? Because we first rescale the data before computing the sample covariance matrix. When we rescale the data, it is done such that every column (variable) gets mean 0, and variance 1.



# PCA MATH TESTING

```{r}
X_iris <- iris[,-5] %>% scale() # Drop Species col

# Calculate sample covariance matrix
S_iris <- 1/nrow(X_iris) * t(X_iris) %*% X_iris # Possibly divide by nrow(X_iris)-1

U_iris <- eigen(S_iris)

# Control calculation for the Eigenvalues (It worked!)
#S_iris %*% U_iris$vectors[,1]
#U_iris$values[1] * U_iris$vectors[,1]

# Calculate the new coordinates of the observations when using PC1 and PC2
# Also called scores
Z_iris_2 <- X_iris %*% U_iris$vectors[,c(1,2)]

# Plot new coordinates
plot(Z_iris_2)
```

# Old code

```{r}
# -V- NOT REQUIRED -V-

# Calculate loadings, or scores, for PC1 and PC2
#Z_crime_2 <- X_crime %*% U_crime$vectors[,c(1,2)]

#plot(Z_crime_2)

# Calculate approximate original data
#X_crime_approx <- Z_crime_2 %*% t(U_crime$vectors[,c(1,2)]) + scaler$mean

# -^- NOT REQUIRED -^-
```



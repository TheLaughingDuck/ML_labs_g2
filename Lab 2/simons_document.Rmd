---
title: "Simons_document"
author: "Simon Jorstedt"
date: "`r Sys.Date()`"
output: pdf_document
---


# Assignment 3

## Setup

```{r}
library(magrittr)
library(dplyr)
library(caret)

crime_df <- read.csv("communities.csv")
```

## Assignment 3.1
We are given some crime data. From analysing it using PCA, we find that the first component (PC1) explains $98.574$% of the variance, and the second component (PC2) explains $0.396$% of the variance in the data. As such, only one component is needed to capture at least $95$% of the variance in the data.

```{r, echo=F}
# Assignment 3.1

X <- crime_df %>%
  select(-"ViolentCrimesPerPop") %>%
  scale()

S <- (1/nrow(X)) * t(X) %*% X

# Find eigenvalues and vectors
eigen(S)

result <- prcomp(crime_df)
lambda <- result$sdev^2
lambda

sprintf("%2.3f",lambda/sum(lambda)*100)
screeplot(result)

```

## Assignment 3.2

```{r}
# Assignment 3.2

PCA_2 <- princomp(crime_df)

# U contains the PC loadings
# The eigenvectors basically (columnwise)
U <- PCA_2$loadings

plot(U[,1], main="Fig 3.2. Traceplot, PC1")
```

In Figure 3.2 we see that the first feature of PC1 (state) carries by far the most explanatory power. The four following ones are population, household size, raceb, racew. These features might be related to each other.

Next, in Figure 3.3 we plot the PC scores of PC1 and PC2, and map the color of points to the Violent Crimes per Population feature.

```{r}
plot(U[,1], U[,2], main="Fig 3.3. PC Scores")
```

## Assignment 3.3

```{r, echo=F}
# Assignment 3.3

## Split data into train and test
n = nrow(crime_df)
set.seed(12345)
id=sample(1:n, floor(n*0.5))
train=crime_df[id,]
test=crime_df[-id,]

```

```{r}
# Establish Scaling
scaling <- train %>% preProcess()

# Scale train and test data
train <- predict(scaling, train)
test <- predict(scaling, test)

# Train lin reg model
model1 <- lm(data = train,
             formula = ViolentCrimesPerPop ~ .)

# Compute train error (MSE)
train_mse <- mean((train$ViolentCrimesPerPop - model1$fitted.values)^2)

# Predict new responses for the test data
test_pred <- predict(model1,
                     test[,-which(names(test) == "ViolentCrimesPerPop")])
test_mse <- mean((test$ViolentCrimesPerPop - test_pred)^2)

cat("Train mse:", train_mse, "\n")
cat("Test mse:", test_mse, "\n")
```

## Assignment 3.4

```{r}
## Assignment 3.4

train_noresponse <- train[,-which(names(train) == "ViolentCrimesPerPop")]
y_true_train <- train[,which(names(train) == "ViolentCrimesPerPop")]

test_noresponse <- test[,-which(names(test) == "ViolentCrimesPerPop")]
y_true_test <- test[,which(names(test) == "ViolentCrimesPerPop")]

train_errors <- c()
test_errors <- c()

# cost function
# data should NOT contain the response variable
# No intercept is included in the underlying model
cost_linreg <- function(theta){
  
  # Calculate train error
  y_pred_train <- as.matrix(train_noresponse) %*% theta
  train_cost <- mean((y_pred_train - y_true_train)^2)
  train_errors <- c(train_errors, train_cost)
  
  # Calculate test error
  y_pred_test <- as.matrix(test_noresponse) %*% theta
  test_cost <- mean((y_pred_test - y_true_test)^2)
  test_errors <- c(test_errors, test_cost)
  
  print(train_errors)
  return(train_cost)
}

optim_object <- optim(rep(0, 100), method="BFGS", fn = cost_linreg, control = list(trace=T))

# Iterate and stuff
# theta <- rep(0, 100)
# train_errors <- c()
# test_errors <- c()
# for(i in 1:1000){
#   cat(i, " ")
#   optim_object <- optim(theta, method="BFGS", fn = cost_linreg)
#   
#   # Compute and store train error
#   train_prediction <- as.matrix(train_noresponse) %*% optim_object$par
#   train_errors <- c(train_errors, mean((train_prediction - y_true)^2))
#   
#   # Compute and store test error
#   test_noresponse <- test[,-which(names(test) == "ViolentCrimesPerPop")]
#   test_prediction <- as.matrix(test_noresponse) %*% optim_object$par
#   test_errors <- c(test_errors, mean((test_prediction - y_true)^2))
#   
#   # Update theta
#   theta <- optim_object$par
# }

#ylim <- c(min(train_errors, test_errors), max(train_errors, test_errors))
plot(test_errors, type="l", col="red", ylim = ylim)
points(train_errors, type="l", col="blue")
```



# Questions
What is the difference between `prcomp` and `princomp`? Why do we redo the PCA after we have already done it in 3.1?

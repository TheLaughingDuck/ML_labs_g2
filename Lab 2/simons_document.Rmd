---
title: "Simons_document"
author: "Simon Jorstedt"
date: "`r Sys.Date()`"
output: pdf_document
---


# Assignment 3

## Setup

```{r}
library(magrittr)
library(dplyr)

crime_df <- read.csv("communities.csv")

crime_df %>% View()
```

## Assignment 3.1
We are given some crime data. From analysing it using PCA, we find that the first component (PC1) explains $98.574$% of the variance, and the second component (PC2) explains $0.396$% of the variance in the data. As such, only one component is needed to capture at least $95$% of the variance in the data.

```{r, echo=F}
# Assignment 3.1

X <- crime_df %>%
  select(-"ViolentCrimesPerPop") %>%
  scale()

S <- (1/nrow(X)) * t(X) %*% X

# Find eigenvalues and vectors
eigen(S)

result <- prcomp(crime_df)
lambda <- result$sdev^2
lambda

sprintf("%2.3f",lambda/sum(lambda)*100)
screeplot(result)

```

## Assignment 3.2

```{r}
# Assignment 3.2

PCA_2 <- princomp(crime_df)

# U contains the PC loadings
# The eigenvectors basically (columnwise)
U <- PCA_2$loadings

plot(U[,1], main="Fig 3.2. Traceplot, PC1")
```

In Figure 3.2 we see that the first feature of PC1 (state) carries by far the most explanatory power. The four following ones are population, household size, raceb, racew. These features might be related to each other.

Next, in Figure 3.3 we plot the PC scores of PC1 and PC2, and map the color of points to the Violent Crimes per Population feature.

```{r}
plot(U[,1], U[,2], main="Fig 3.3. PC Scores")
```

## Assignment 3.3

```{r, echo=F}
# Assignment 3.3

## Split data into train and test
n = nrow(crime_df)
set.seed(12345)
id=sample(1:n, floor(n*0.5))
train=crime_df[id,]
test=crime_df[-id,]

```

```{r}
# Scaling
scaled_train <- train %>% scale()

# Get the centering and scale numerics
center <- attributes(scaled_train)$"scaled:center"
scale <- attributes(scaled_train)$"scaled:scale"
```



# Questions
What is the difference between `prcomp` and `princomp`? Why do we redo the PCA after we have already done it in 3.1?

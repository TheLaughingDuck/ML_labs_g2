---
title: "Sim_notebook"
author: "Simon Jorstedt"
date: "`r Sys.Date()`"
output: pdf_document
---

# Question 3
We are provided data covering the onset of diabetes within a five year period for a group of individuals. The data consists of nine variables including a binary response variable indicating presence of diabetes or not.

```{r}
library(plotly)
library(magrittr)

# Read data
diab_data <- read.csv("pima-indians-diabetes.csv")
colnames(diab_data) <- c("n_pregnant", "pg_con", "blood_pressure", "skindfold_thickness", "serum_insulin", "bmi", "diab_pedigree", "age", "diabetes")

# Divide data train test?
n_diab = dim(diab_data)[1]

set.seed(7183723)
id_diab_train = sample(1:n_diab, floor(n_diab*0.6))
id_diab_test = setdiff(1:n_diab, id_diab_train)

diab_data_train = diab_data[id_diab_train,]
diab_data_test = diab_data[id_diab_test,]


# Define the logit function
logit <- function(z){
  exp(z) / (1 + exp(z))
}
```


## 3.1
See \textit{Machine Learning - A first course for engineers and scientists} (pp. 45-52) for a discussion on logistic regression.

```{r, eval=F}
## Must apparently be made a base R plot
plot_ly(type="scatter", mode="markers",
        data = diab_data,
        x = ~age,
        y = ~pg_con,
        colors = c("#1f77b4", "#ff7f0e"),
        color = ~factor(x = diab_data$diabetes, labels = c("No diabetes", "Diabetes")),
        legendgrouptitle = list(text = "Diagnosis")) %>%
  layout(title = "Fig 3.1 PGC vs Age, colored by diabetes")
```

We do not think it will be easy to make the distinction using only these two variables. In Figure 3.1 we observe a large cluster of young people (ages ~20-25) that do not have diabetes, along with a significant number of outliers (among the non-diabetes people.) The people with diabetes however are much more spread out, with no smaller clusters. It appears as though people with diabetes tend to have slightly larger Plasma Glucose Concentration (PGC) values than people without diabetes. Thus it does appear as though there is some precedent for using only PGC values and Age as explanatory variables. It won't be easy or "clear-cut" though.



# 3.2
```{r}
model1 <- glm(formula = diabetes ~pg_con + age,
    family = binomial(link = "logit"),
    data = diab_data)

summary(model1)

# Calculate
diab_data <- diab_data %>%
  mutate(predicted_05 = as.integer(fitted(model1) >= 0.5)) %>%
  mutate(predicted_02 = as.integer(fitted(model1) >= 0.2)) %>%
  mutate(predicted_08 = as.integer(fitted(model1) >= 0.8))

# Misclassification error
mis_class_error <- 1- (diab_data$diabetes == diab_data$predicted_05) %>% sum() / nrow(diab_data)

cat("Misclassification error:", mis_class_error, "\n")
```

The resulting model is

$$g(\boldsymbol{x}) = \frac{e^{z}}{1+e^{z}}$$

where

$$z = \boldsymbol{\theta}^T \boldsymbol{x} = (`r round(model1$coefficients, 4)`) \cdot (1, x_{\text{age}}, x_{\text{pg}})^T$$


```{r, eval=F}
# New plot

plot_ly(type="scatter", mode="markers",
        data = diab_data,
        x = ~age,
        y = ~pg_con,
        split = ~predicted)

# Add curve
```

The quality of this classification is ok, not perfect. The resulting predictions is visually precisely what could be expected when analysing Figure 3.1. The model essentially just takes what was stated before, about diabetic people being overrepresented among people with high PGC values. This means that there will be a high true/false pos/neg probability.

# 3.3
Add curve

# 3.4

```{r, eval=F}
# Plotly named colours
# https://community.plotly.com/t/plotly-colours-list/11730/3


# r = 0.2
p_r02 <- plot_ly(type="scatter", mode="markers",
        data = diab_data,
        x = ~age,
        y = ~pg_con,
        colors = c("#1f77b4", "#ff7f0e"),
        color = ~factor(x = diab_data$predicted_02, labels = c("No diabetes", "Diabetes")),
        legendgrouptitle = list(text = "Diagnosis")) %>%
  layout(title = "Fig 3.2 PGC vs Age, colored by predicted diagnosis (r=0.2)")
# add curve


# r = 0.8
p_r08 <- plot_ly(type="scatter", mode="markers",
        data = diab_data,
        x = ~age,
        y = ~pg_con,
        colors = c("#1f77b4", "#ff7f0e"),
        color = ~factor(x = diab_data$predicted_08, labels = c("No diabetes", "Diabetes")),
        showlegend = FALSE) %>%
  layout(title = "Fig 3.? PGC vs Age, colored by predicted diagnosis (r=0.8)")
# add curve


subplot(p_r02, p_r08) %>%
  layout(title = "Fig 3.4")
```

Comment on Figure 3.4.


## 3.5

```{r, eval=F}
# Create new variables z_1, ... z_5
diab_data <- diab_data %>%
  mutate(z1 = pg_con^4 * age^0, 
         z2 = pg_con^3 * age^1,
         z3 = pg_con^2 * age^2,
         z4 = pg_con^1 * age^3,
         z5 = pg_con^0 * age^4)

# New model
model2 <- glm(formula = diabetes ~ pg_con + age + z1 + z2 + z3 + z4 + z5,
    family = binomial(link = "logit"),
    data = diab_data)

summary(model2)

diab_data_newmodel <- diab_data %>%
  mutate(predicted_z_05 = as.integer(fitted(model2) >= 0.5))


# Test plot
p_new <- plot_ly(type="scatter", mode="markers",
        data = diab_data_newmodel,
        x = ~age,
        y = ~pg_con,
        colors = c("#1f77b4", "#ff7f0e"),
        color = ~factor(x = diab_data_newmodel$predicted_z_05, labels = c("No diabetes", "Diabetes"))) %>%
  layout(title = "Fig 3.? PGC vs Age, colored by predicted diagnosis (r=0.5)")

p_new
```



```{r, eval=F}
fake_data <- data.frame(age=runif(1000, 0, 80), pg_con=runif(1000, 0, 200)) %>%
  mutate(z1 = pg_con^4 * age^0,
         z2 = pg_con^3 * age^1,
         z3 = pg_con^2 * age^2,
         z4 = pg_con^1 * age^3,
         z5 = pg_con^0 * age^4) %>%
  mutate(predicted = as.integer(predict.glm(model2, newdata = .) %>% logit() >= 0.5))

# FAKE Plot
plot_ly(type="scatter", mode="markers",
        data = fake_data,
        x = ~age,
        y = ~pg_con,
        colors = c("#1f77b4", "#ff7f0e"),
        color = ~factor(x = fake_data$predicted, labels = c("No diabetes", "Diabetes"))) %>%
  layout(title = "Fig 3.? PGC vs Age, colored by predicted diagnosis (r=0.5)")
```


---
title: "hugos_notebook"
author: "Hugo"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Assignment 1 : Handwritten digit recognition with K-nearest neighbors.

## 1. 
Import the data into R and divide it into training, validation and test sets (50%/25%/25%) by using the partitioning principle specified in the lecture slides. 

```{r 1.1}
# Read data
digit_data <- read.csv("optdigits.csv", header=FALSE)

# Partition data (according to Oleg)
n = dim(digit_data)[1]

set.seed(12345)
id = sample(1:n, floor(n*0.5))
digits_train = digit_data[id,]
id1 = setdiff(1:n, id)

set.seed(12345)
id2 = sample(id1, floor(n*0.25))
digits_valid = digit_data[id2,]
id3 = setdiff(id1,id2)
digits_test = digit_data[id3,]

#Is feature scalling needed ??
#Slide 15 in lecture 1d
```

## 2. 
Use training data to fit 30-nearest neighbor classifier with function kknn() and kernel=”rectangular” from package kknn and estimate:
• Confusion matrices for the training and test data (use table())
• Misclassification errors for the training and test data
Comment on the quality of predictions for different digits and on the overall
prediction quality.

```{r 1.2}
library(kknn)
library(caret)
library(shipunov)

#Fitting the classifier
digits_kknn <- kknn(formula = as.factor(V65) ~ . , train = digits_train, test = digits_test, k = 30, kernel = "rectangular")



#Confusion Matrix: 
fit <- fitted(digits_kknn)
predictions <- predict(digits_kknn, type='prob')
predictions
print("Confusion matrix:")
conf_mat <- table(digits_test$V65, fit)
conf_mat
cat("\n")
shipunov::Misclass(fit, digits_test$V65)


```

## 3.
Find any 2 cases of digit “8” in the training data which were easiest to classify and 3 cases that were hardest to classify (i.e. having highest and lowest probabilities of the correct class). Reshape features for each of these cases as matrix 8x8 and visualize the corresponding digits (by using e.g. heatmap() function with parameters Colv=NA and Rowv=NA) and comment on whether these cases seem to be hard or easy to recognize visually.

```{r 1.3}

```

## 4.
Fit a K-nearest neighbor classifiers to the training data for different values of K K = 1,2, … , 30 and plot the dependence of the training and validation misclassification errors on the value of K (in the same plot). How does the model complexity change when K increases and how does it affect the training and validation errors? Report the optimal K K according to this plot. Finally, estimate the test error for the model having the optimal K, compare it with the training and validation errors and make necessary conclusions about the model quality.

```{r 1.4}

```

## 5.
Fit K-nearest neighbor classifiers to the training data for different values of K K = 1,2, … , 30, compute the error for the validation data as cross-entropy ( when computing log of probabilities add a small constant within log, e.g. 1e-15, to avoid numerical problems) and plot the dependence of the validation error on the value of K K. What is the optimal K K value here? Assuming that response has multinomial distribution, why might the cross-entropy be a more suitable choice of the error function than the misclassification error for this problem?

```{r 1.5}

```

